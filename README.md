
# <div style="text-align: center;"><img src="./figure/SpaceR.png" width="60" height="60" /> </div>
# SpaceR: Reinforcing MLLMs in Video Spatial Reasoning  
[ğŸ“– Paper](https://github.com/OuyangKun10/SpaceR/blob/main/SpaceR_Preprint.pdf) [ğŸ¤— SpaceR](https://huggingface.co/RUBBISHLIKE/SpaceR) [ğŸ“Š SpaceR-151k](https://huggingface.co/datasets/RUBBISHLIKE/SpaceR-151k)


ğŸ“… News

ğŸš€ [05/19/2025] We release [SpaceR-151k](https://huggingface.co/datasets/RUBBISHLIKE/SpaceR-151k) dataset.

ğŸš€ [05/10/2025] We release [SpaceR](https://huggingface.co/RUBBISHLIKE/SpaceR) checkpoint.

ğŸš€ [04/29/2025] We release [SR-91k](https://huggingface.co/datasets/RUBBISHLIKE/SpaceR-151k) dataset.

ğŸš€ [04/10/2025] We update the training framework of SpaceR.

ğŸš€ [04/02/2025] We share the paper SpaceR on arxiv.

ğŸš€ [03/31/2025] We release evluation and training code.



# SpaceR
The first MLLM empowered by SG-RLVR for video spatial reasoning

ğŸ† Performance Comparison 
<img src="./figure/overall_performance.png"/>

**Data Statistics of SpaceR-151k**
<img src="./figure/data_statistics.png"/>

**QA Examples of SR-91k**

<img src="./figure/QA_visual.png"/>

We curate SpaceR-151k dataset and propose SpaceR. It achieves promising gains in VSI-Bench, SPAR-Bench and STI-Bench.  **NOTE** We have excluded [videos](https://github.com/OuyangKun10/SpaceR/blob/main/exclude_list.txt) used in VSI-Bench to prevent data leakage.

## Training
```bash
git clone https://github.com/OuyangKun10/SpaceR.git
cd SpaceR/SpaceR

# build environment
conda create -n SpaceR python=3.11 
conda activate SpaceR
bash setup.sh

# qwen video extraction setting, e.g., max frames, resolutions
# Use the [decord] feature to improve speed
cd src/qwen-vl-utils
pip install -e .[decord]
cd ..
```
**Data Preparation**:

1. Download [SpaceR-151k dataset](https://huggingface.co/datasets/RUBBISHLIKE/SpaceR-151k).

2. Decompress it
   
```bash
bash decompress.sh
```

   
**Training script for SpaceR**
```bash
bash ./src/scripts/run_SpaceR_SG_RLVR.sh
```
## Evaluation

**SpaceR-Eval**

## Setup

1.  **Environment:** Python 3.8+, CUDA-enabled GPUs.
2.  **Install Libraries:**
    ```bash
    pip install torch pandas numpy pillow accelerate transformers sentencepiece decord flash-attn --no-build-isolation
    ```
3.  **Dataset:** VSI-Bench STI-Bench, SPAR-Bench, Video-MME, TempCompass, LongVideoBench


## Usage
    ```bash
    python evaluate.py
    ```

**Citation:**

```
@article{ouyang2025spacerreinforcingmllmsvideo,
      title={SpaceR: Reinforcing MLLMs in Video Spatial Reasoning}, 
      author={Kun Ouyang and Yuanxin Liu and Haoning Wu and Yi Liu and Hao Zhou and Jie Zhou and Fandong Meng and Xu Sun},
      journal={arXiv preprint arXiv:2504.01805},
      year={2025},
}
```

## License
* The code in this repo is released under the [CC BY-NC 4.0](https://github.com/OuyangKun10/SpaceR/blob/main/LICENSE) License. 
* The usage of SpaceR-151k dataset and SpaceR model weights must strictly follow [CC BY-NC 4.0](https://github.com/OuyangKun10/SpaceR/blob/main/LICENSE) License. 


